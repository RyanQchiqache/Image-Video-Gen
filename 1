import torch
import torchvision
import torchvision.transforms as T

from tqdm import tqdm
from loguru import logger
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torch.nn import CrossEntropyLoss
from torch.optim import Adam
from datasets import load_dataset
from vision_transformers import Vit
from torch.cuda.amp import GradScaler, autocast


DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

###############################################################
# CONFIG
###############################################################
BATCHSIZE=64
EPOCHS=64
LR=3e-4
RESIZE=(320,320)
DROPOUT=0.1
ATT_DROPOUIT=0.1
EM_DIM=128
NUM_CLASSES=1000
MLP_SIZE=128
NUM_LAYERS=8
NUM_HEADS=8


################################################################
# DATASET
################################################################
# Login using e.g. `huggingface-cli login` to access this dataset
train_dataset = load_dataset("ILSVRC/imagenet-1k", split="train")
val_dataset = load_dataset("ILSVRC/imagenet-1k", split="validation")


##################################################################
# TRANSFORM & DATALOADER
##################################################################

transforms = T.Compose([
        T.RandomRotation(degrees=0.5),
        T.ToTensor(),
        T.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),
    ])


def hf_transform(example):
    image = example["image"]
    label = example["label"]
    image = transforms(image)
    return {"pixel_values": image, "labels": label}

train_dataset.set_transform(hf_transform)
val_dataset.set_transform(hf_transform)

train_loader = DataLoader(train_dataset, batch_size=BATCHSIZE, shuffle=True, num_workers=4, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=BATCHSIZE, shuffle=False)

###################################################################
# MODEL, OPTIM, CRITERION
###################################################################
model = ViT(
        in_height=320,
        in_width=320,
        out_height=20,
        out_width=20,
        in_channels=3,
        emb_dim=128,
        num_heads=8,
        mlp_size=128,
        dropout=0.1,
        att_dropout=0.1,
        num_classes=1000,
        num_layers=8
    ).to(DEVICE)# should i give it all the parameters now or later
criterion = CrossEntropyLoss()
optim = Adam(model.parameters(), lr=LR)
scaler = GradScaler()
writer = SummaryWriter()

logger.info(f"model, loss and optimizer are loaded")

###################################################################
# iou and miou
###################################################################
def iou(pred, target, classe):
    if pred.ndim > target.ndim:
        pred = pred.argmax(dim=1)

    pred_c = (pred == classe)
    target_c = (target == classe)

    intersection = (pred_c & target_c).sum().float()
    union = (pred_c | target_c).sum().float()
    
    return intersection / (union + 1e-8)

def miou(pred, target, classes):
    
    return torch.mean(torch.stack([iou(pred, target, classes) for classes in range(NUM_CLASSES)]))

def accuracy1(logits, targets):
    preds = logits.argmax(dim=1)
    return (preds == targets).float().mean()

def accuracy5(logits, targets, k):
    _, topk = logits.topk(k, dim=1)
    targets = target.view(-1, 1)
    return (targets == topk).any(dim=1).float().mean()

#####################################################################
# VALIDATE
####################################################################
def validation_step(model, val_loader, device, criterion, k ):
    model.eval()
    
    total_loss = 0
    topk1 = 0
    topk5 = 0
    num_batches = 0
    with torch.no_grad():
        for batches in tqdm(val_loader, desc="Validation"):
            images = batches["pixel_values"].to(device)
            labels = batches["labels"].to(device)

            output = model(images)

            loss = criterion(output, labels)
            
            total_loss += loss.item()
            topk1 += accuracy1(output, images).item()
            topk5 += accuracy5(output, images, k).item()

            num_batches += 1

        return {
                "Total loss": total_loss / num_batches,
                "top1 accuracy": topk1 / num_batches,
                "top5 accuracy": topk5 / num_batches

                }



    
#####################################################################
# Training
#####################################################################

logger.info("Starting training...")

for epoch in range(EPOCHS):
    model.train()
    _loss = 0
    for batch in tqdm(train_loader, desc="Training"):
        images, labels = batch["pixel_values"].to(DEVICE), batch["labels"].to(DEVICE)


        optim.zero_grad(set_to_none=True)

        with autocast():
            output = model(images)
            loss = criterion(output, labels)
        
        
        scaler.scale(loss).backward()
        scaler.step(optim)
        scaler.update()

        _loss += loss.item()

    total_loss = _loss / len(train_loader)

    validation = validation_step(model, val_loader, DEVICE, criterion, k=5)
        
    logger.info(f"Epoch {epoch+1} |" 
                f"Training Loss: {total_loss:.4f}"
                f"Loss Val: {validation["Total loss"]:.4f} |"
                f"Topk1 accuracy: {validation["top1 accuracy"]:.4f} |"
                f"Topk5 accuracy: {validation["top5 accuracy"]:.4f} |"
                    )

    writer.add_scalar("Loss/train", train_loss, epoch)
    writer.add_scalar("Loss/val", val_metrics["val_loss"], epoch)
    writer.add_scalar("Accuracy/top1", val_metrics["top1"], epoch)
    writer.add_scalar("Accuracy/top5", val_metrics["top5"], epoch)
        
writer.close()

        
        
        

        




























